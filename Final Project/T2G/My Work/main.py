# Code inspired by the works of Q. Guo, Z. Jin, X. Qiu, W. Zhang, D. Wipf, and Z. Zhang, “CycleGT: Unsupervised Graph-to-Text and Text-to-Graph Generation via Cycle Training,” arXiv:2006.04702 [cs], Dec. 2020, Accessed: May 05, 2022. [Online]. Available: http://arxiv.org/abs/2006.04702
# Github code of Guq et. al. https://github.com/QipengGuo/CycleGT

# Code insipred by the works of C. Raffel et al., “Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer,” arXiv:1910.10683 [cs, stat], Jul. 2020, Accessed: May 05, 2022. [Online]. Available: http://arxiv.org/abs/1910.10683

import argparse



def main():
    parser = argparse.ArgumentParser()
    #parser.add_argument('--config', type=str, default='config.yaml')
    #args = parser.parse_args()
    #config = yaml.load(open(args.config, 'r'))
    #_config = copy.deepcopy(config)
    #random.seed(config['main']['seed'])
    #torch.manual_seed(config['main']['seed'])
    #np.random.seed(config['main']['seed'])
    #torch.cuda.manual_seed_all(config['main']['seed'])
    #torch.backends.cudnn.deterministic = True
    #torch.backends.cudnn.benchmark = False

    #vocab = prep_data(config['main'])
    #torch.save({'vocab':vocab}, 'tmp_vocab.pt')
    #train('train', config)
    return

if __name__=='__main__':
    main()
    #multi_run()
